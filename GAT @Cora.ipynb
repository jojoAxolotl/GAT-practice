{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23fd8b74",
   "metadata": {},
   "source": [
    "## Part 1: Understanding your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd4c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I always like to structure my imports into Python's native libs,\n",
    "# stuff I installed via conda/pip and local file imports (but we don't have those here)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Visualization related imports\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "\n",
    "# Main computation libraries\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "\n",
    "# Deep learning related imports\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea9cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Contains constants needed for data loading and visualization.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import enum\n",
    "\n",
    "\n",
    "# Supported datasets - only Cora in this notebook\n",
    "class DatasetType(enum.Enum):\n",
    "    CORA = 0\n",
    "\n",
    "    \n",
    "# Networkx is not precisely made with drawing as its main feature but I experimented with it a bit\n",
    "class GraphVisualizationTool(enum.Enum):\n",
    "    NETWORKX = 0,\n",
    "    IGRAPH = 1\n",
    "\n",
    "\n",
    "# We'll be dumping and reading the data from this directory\n",
    "DATA_DIR_PATH = os.path.join(os.getcwd(), 'data')\n",
    "CORA_PATH = os.path.join(DATA_DIR_PATH, 'cora')  # this is checked-in no need to make a directory\n",
    "\n",
    "#\n",
    "# Cora specific constants\n",
    "#\n",
    "\n",
    "# Thomas Kipf et al. first used this split in GCN paper and later Petar Veličković et al. in GAT paper\n",
    "CORA_TRAIN_RANGE = [0, 140]  # we're using the first 140 nodes as the training nodes\n",
    "CORA_VAL_RANGE = [140, 140+500]\n",
    "CORA_TEST_RANGE = [1708, 1708+1000]\n",
    "CORA_NUM_INPUT_FEATURES = 1433\n",
    "CORA_NUM_CLASSES = 7\n",
    "\n",
    "# Used whenever we need to visualzie points from different classes (t-SNE, CORA visualization)\n",
    "cora_label_to_color_map = {0: \"red\", 1: \"blue\", 2: \"green\", 3: \"orange\", 4: \"yellow\", 5: \"pink\", 6: \"gray\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09360729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's define these simple functions for loading/saving Pickle files - we need them for Cora\n",
    "\n",
    "# All Cora data is stored as pickle\n",
    "def pickle_read(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "def pickle_save(path, data):\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(data, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d3f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Cora!\n",
    "\n",
    "# We'll pass the training config dictionary a bit later\n",
    "def load_graph_data(training_config, device):\n",
    "    dataset_name = training_config['dataset_name'].lower()\n",
    "    should_visualize = training_config['should_visualize']\n",
    "\n",
    "    if dataset_name == DatasetType.CORA.name.lower():\n",
    "\n",
    "        # shape = (N, FIN), where N is the number of nodes and FIN is the number of input features\n",
    "        node_features_csr = pickle_read(os.path.join(CORA_PATH, 'node_features.csr'))\n",
    "        # shape = (N, 1)\n",
    "        node_labels_npy = pickle_read(os.path.join(CORA_PATH, 'node_labels.npy'))\n",
    "        # shape = (N, number of neighboring nodes) <- this is a dictionary not a matrix!\n",
    "        adjacency_list_dict = pickle_read(os.path.join(CORA_PATH, 'adjacency_list.dict'))\n",
    "\n",
    "        # Normalize the features (helps with training) will mentioned at the next cell\n",
    "        node_features_csr = normalize_features_sparse(node_features_csr)\n",
    "        num_of_nodes = len(node_labels_npy)\n",
    "\n",
    "        # shape = (2, E), where E is the number of edges, and 2 for source and target nodes. Basically edge index\n",
    "        # contains tuples of the format S->T, e.g. 0->3 means that node with id 0 points to a node with id 3.\n",
    "        topology = build_edge_index(adjacency_list_dict, num_of_nodes, add_self_edges=True)\n",
    "                   # will be mentioned in the next 2 cell\n",
    "        # Note: topology is just a fancy way of naming the graph structure data \n",
    "        # (aside from edge index it could be in the form of an adjacency matrix)\n",
    "\n",
    "        if should_visualize:  # network analysis and graph drawing\n",
    "            plot_in_out_degree_distributions(topology, num_of_nodes, dataset_name)  # we'll define these in a second\n",
    "            visualize_graph(topology, node_labels_npy, dataset_name)\n",
    "\n",
    "        # Convert to dense PyTorch tensors\n",
    "\n",
    "        # Needs to be long int type because later functions like PyTorch's index_select expect it\n",
    "        topology = torch.tensor(topology, dtype=torch.long, device=device)\n",
    "        node_labels = torch.tensor(node_labels_npy, dtype=torch.long, device=device)  # Cross entropy expects a long int\n",
    "        node_features = torch.tensor(node_features_csr.todense(), device=device)\n",
    "\n",
    "        # Indices that help us extract nodes that belong to the train/val and test splits\n",
    "        train_indices = torch.arange(CORA_TRAIN_RANGE[0], CORA_TRAIN_RANGE[1], dtype=torch.long, device=device)\n",
    "        val_indices = torch.arange(CORA_VAL_RANGE[0], CORA_VAL_RANGE[1], dtype=torch.long, device=device)\n",
    "        test_indices = torch.arange(CORA_TEST_RANGE[0], CORA_TEST_RANGE[1], dtype=torch.long, device=device)\n",
    "\n",
    "        return node_features, node_labels, topology, train_indices, val_indices, test_indices\n",
    "    else:\n",
    "        raise Exception(f'{dataset_name} not yet supported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d76914a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature normalization on Cora:\n",
    "\n",
    "# It's basically making Cora's binary node feature vectors sum up to 1. \n",
    "# Example if we had [1, 0, 1, 0, 1] (Cora's feature vectors are longer as we'll soon see \n",
    "# but let's take this one for the time being), it will get transformed into [0.33, 0, 0.33, 0, 0.33]. \n",
    "# Simple as that. It's always harder to understand the actual implementation, but conceptually, it's a piece of cake.\n",
    "\n",
    "def normalize_features_sparse(node_features_sparse):\n",
    "    assert sp.issparse(node_features_sparse), f'Expected a sparse matrix, got {node_features_sparse}.'\n",
    "\n",
    "    # Instead of dividing (like in normalize_features_dense()) we do multiplication with inverse sum of features.\n",
    "    # Modern hardware (GPUs, TPUs, ASICs) is optimized for fast matrix multiplications! ^^ (* >> /)\n",
    "    # shape = (N, FIN) -> (N, 1), where N number of nodes and FIN number of input features\n",
    "    node_features_sum = np.array(node_features_sparse.sum(-1))  # sum features for every node feature vector\n",
    "\n",
    "    # Make an inverse (remember * by 1/x is better (faster) then / by x)\n",
    "    # shape = (N, 1) -> (N)\n",
    "    node_features_inv_sum = np.power(node_features_sum, -1).squeeze()\n",
    "\n",
    "    # Again certain sums will be 0 so 1/0 will give us inf so we replace those by 1 which is a neutral element for mul\n",
    "    node_features_inv_sum[np.isinf(node_features_inv_sum)] = 1.\n",
    "\n",
    "    # Create a diagonal matrix whose values on the diagonal come from node_features_inv_sum\n",
    "    diagonal_inv_features_sum_matrix = sp.diags(node_features_inv_sum)\n",
    "\n",
    "    # We return the normalized features.\n",
    "    return diagonal_inv_features_sum_matrix.dot(node_features_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d7a920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build up that edge index\n",
    "\n",
    "def build_edge_index(adjacency_list_dict, num_of_nodes, add_self_edges=True):\n",
    "    source_nodes_ids, target_nodes_ids = [], []\n",
    "    seen_edges = set()\n",
    "\n",
    "    for src_node, neighboring_nodes in adjacency_list_dict.items():\n",
    "        for trg_node in neighboring_nodes:\n",
    "            # if this edge hasn't been seen so far we add it to the edge index (coalescing - removing duplicates)\n",
    "            if (src_node, trg_node) not in seen_edges:  # it'd be easy to explicitly remove self-edges (Cora has none..)\n",
    "                source_nodes_ids.append(src_node)\n",
    "                target_nodes_ids.append(trg_node)\n",
    "\n",
    "                seen_edges.add((src_node, trg_node))\n",
    "\n",
    "    if add_self_edges:\n",
    "        source_nodes_ids.extend(np.arange(num_of_nodes))\n",
    "        target_nodes_ids.extend(np.arange(num_of_nodes))\n",
    "\n",
    "    # shape = (2, E), where E is the number of edges in the graph\n",
    "    edge_index = np.row_stack((source_nodes_ids, target_nodes_ids))\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# This one should be fairly simple - we just accumulate the edges in this format:\n",
    "# [[0, 1], [2, 2], ...] where [s, t] tuple basically defines an edge where node s (source) points to node t (target).\n",
    "# Other popular format (used in my other 2 implementations) is the adjacency matrix,\n",
    "# but those take up way more memory (O(N^2) to be precise, compare that to O(E) for the edge index structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6174e2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 1433]) torch.float32\n",
      "torch.Size([2708]) torch.int64\n",
      "torch.Size([2, 13264]) torch.int64\n",
      "torch.Size([140]) torch.int64\n",
      "torch.Size([500]) torch.int64\n",
      "torch.Size([1000]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# finally let's try and load it. We should also analyze the shapes - that's always a good idea.\n",
    "\n",
    "# Let's just define dummy visualization functions for now - just to stop Python interpreter from complaining!\n",
    "# We'll define them in a moment, properly, I swear.\n",
    "\n",
    "def plot_in_out_degree_distributions():\n",
    "    pass\n",
    "\n",
    "def visualize_graph():\n",
    "    pass\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # checking whether you have a GPU\n",
    "\n",
    "config = {\n",
    "    'dataset_name': DatasetType.CORA.name,\n",
    "    'should_visualize': False\n",
    "}\n",
    "\n",
    "node_features, node_labels, edge_index, train_indices, val_indices, test_indices = load_graph_data(config, device)\n",
    "\n",
    "print(node_features.shape, node_features.dtype)\n",
    "print(node_labels.shape, node_labels.dtype)\n",
    "print(edge_index.shape, edge_index.dtype)\n",
    "print(train_indices.shape, train_indices.dtype)\n",
    "print(val_indices.shape, val_indices.dtype)\n",
    "print(test_indices.shape, test_indices.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00af7753",
   "metadata": {},
   "source": [
    "Nice! Analyzing the shapes we see the following:\n",
    "\n",
    "* Cora has 2708 nodes\n",
    "* Each node has 1433 features (check out data_loading.py for much more detail)\n",
    "* We have 13264 edges! (including the self edges)\n",
    "* We have 140 training nodes\n",
    "* We have 500 val nodes\n",
    "* We have 1000 test nodes\n",
    "\n",
    "\n",
    "Additionally almost all of the data is of int 64 type. \n",
    "Why? Well it's a constraint that PyTorch is imposing upon us. \n",
    "The loss function nn.CrossEntropyLoss and index_select functions require torch.long \n",
    "(i.e. 64 bit integer) - that's it.\n",
    "\n",
    "* node_labels is int64 because of nn.CrossEntropyLoss\n",
    "* other vars are int64 because of index_select\n",
    "\n",
    "*On the \"side note\", it's always a good idea to test your code as you're progressing.*\n",
    "\n",
    "Data loading is completely orthogonal to the rest of this notebook so we can test it, standalone, and make sure the shapes and datatypes make sense. I use this strategy while developing projects like this one (and in general)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69faf5fe",
   "metadata": {},
   "source": [
    "## Part 2: Understanding GAT's inner workings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e07f1",
   "metadata": {},
   "source": [
    "http://127.0.0.1:8888/notebooks/The%20Annotated%20GAT%20(Cora).ipynb#Part-2:-Understanding-GAT's-inner-workings-%F0%9F%92%BB%F0%9F%A6%84"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
